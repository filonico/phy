# BUILDING A TREE IN A BAYESIAN FRAMEWORK

<br/>
<br/>

## INTRO: 

In this lesson we will use MrBayes [(Ronquist et al., 2012)](https://academic.oup.com/sysbio/article/61/3/539/1674894) to understand the underlying concepts of Bayesian Inference in phylogenetics. Remember that in a Bayesian framework we estimate parameters from their posterior distribution, instead of finding the best single estimates as in a Maximum Likelihood framework.

---

<br/>
<br/>

### SUBSAMPLING OUR DATA:


Unfortunately, next steps of this tutorial will be very computanional intensive, for this reason we need to subsample our 1-to-1 gblocked alignments. We can randomly chose *n* alignments very easly using a for loop and some simple bash commands:

```
mkdir -p Analyses/BI/Alignments
brew install coreutils #For MacOS users
for i in $(ls Analyses/1-to-1_Alignments/gblock | shuf -n 5); do varAL=$( find . -name "$i"); cp "$varAL" Analyses/BI/Alignments/; done
```

---

## MSA FORMAT CONVERSION: 

At this stage we have already used ```.fas``` and ```.nxs``` formats for Multiple Sequence Alignment. 
In this lesson we will also need a ```.phy``` - a phylip-formatted file - which is required by [PartitionFinder2](http://www.robertlanfear.com/partitionfinder/).
This format name comes from a very ancient piece of software - called of course [PHYLIP](https://en.wikipedia.org/wiki/PHYLIP) - which is turning 40 this year :-O
It is a very bare bone format which has in the first line the number of species and the number of characters (nucleotides, proteins, ...) separated by a space and subsequently one entry (whether species or specimen) for each line, with the sequence i.d. as the first element followed by a space and then by the sequence itself.

If you want to play with Bash you can write your own scripts to convert from different formats. Something like:

  from ```.nxs``` to ```.fasta```:

```
awk '/MATRIX/,EOF { print $0 }' concatenation.nxs | tail +2 | tr  \\t ' ' | sed -e 's/^ />/' | tr ' ' '\n' | sed '$d' | sed '$d' | sed '$d' > concatenation.fasta
```

  from ```.nxs``` to ```.phy```:

```
nxs=concatenation.nxs;
awk '/MATRIX/,EOF { print $0 }' $nxs | tail +2 | tr  \\t ' ' | sed 's/^ //g' | sed '$d' | sed '$d' | sed '$d' > tmp.phy; 
n_tax=$(head -4 $nxs | tail -1 | awk -F "NTAX=" '{print $2}' | awk '{print $1}');
n_car=$(head -4 $nxs | tail -1 | awk -F "NCHAR=" '{print $2}' | tr -d ";");
echo $n_tax $n_car > first_line.tmp; cat first_line.tmp tmp.phy > concatenation.phy; 
rm *tmp*
```

But usually, Python it's much more efficient for these operations since it's less prone to bugs and most of the time you will find an already tested package that do it for you (saving you time, but if you just want to play with code, you can practice yourself writing your own functions!).

Since we have already installed AMAS we can use again its ```concat``` function but specifyng the phylip output format for the alignment and the Raxml format for the partition file (which will became our ```.cfg``` file):

```
AMAS.py concat -u phylip-int -y raxml -i Analyses/BI/Alignments/OG00000* -f fasta -d aa -p Analyses/BI/My_Partitions.txt -t Analyses/BI/My_concat.phy
```
---

## MODEL SELECTION, AGAIN....

Before the phylogenetic Bayesian Inference (BI), we have to carry out another model selection, mainly for two reasons:

* MrBayes supports slightly different models than ModelFinder (_e.g._ no base frequencies additional parameters)

* even if possible it's really painfull to translate / approximate models from ModelFinder to MrBayes.

We will take advantage of this situation to leverage PartitionFinder2 [(Lanfear et al., 2016)]( https://doi.org/10.1093/molbev/msw260) which can carry out the model selection specifically for MrBayes. This situation teaches us a lesson on usability and how sometimes phylogenetic pipeline consist in a straight process (ModelFinder -> IQ-TREE), but sometimes they result in a quite fragmented workflow with multiple tools and steps in between them.

As previously said the input of PartitionFinder2 are a ```.phy``` and a ```.cfg```.
The latter stands for configuration and is a quite widespread approach to customise analyses while using several pieces of software: all the options are found inside the configuration file, including all the inputs required for the analysis. For convenience, the input alignment is usually placed in the same folder where the configuration file is located, but a path can be specified as well.

For this purpose we have to reformat a bit the our partition file:

```
cat Analyses/BI/My_Partitions.txt | sed 's/^.....//g' | sed 's/$/;/g' > Analyses/BI/partition_finder.cfg
```

Now we have to manually change it following [this](http://www.robertlanfear.com/partitionfinder/tutorial/assets/partition_finder.cfg) pre-formatted configuration. You should already be familiar with many of the options, as they are quite similar to the ones of ModelFinder.
Here is how I configured my ```.cfg``` using ```vim``` :


```
cat Analyses/BI/partition_finder.cfg
## ALIGNMENT FILE ##
alignment = My_concat.phy;

## BRANCHLENGTHS: linked | unlinked ##
branchlengths = linked;

## MODELS OF EVOLUTION: all | allx | mrbayes | beast | gamma | gammai | <list> ##
models = mrbayes;

# MODEL SELECCTION: AIC | AICc | BIC #
model_selection = bic;

## DATA BLOCKS: see manual for how to define ##
[data_blocks]

p1_OG0000031 = 1-151;
p2_OG0000036 = 152-314;
p3_OG0000042 = 315-475;
p4_OG0000061 = 476-805;
p5_OG0000075 = 806-956;

## SCHEMES, search: all | user | greedy | rcluster | rclusterf | kmeans ##
[schemes]

search = rcluster;
```

And run PF specifing the directory where alignments and the cfg file are stored:

```
conda deactivate
conda activate PF-env
python /Users/jacopomartelossi/Desktop/phylogenetic_software/partitionfinder-2.1.1/PartitionFinderProtein.py Analyses/BI/ --raxml --rcluster-max 10
```

The ```--raxml``` flag is necessary to perform the relaxed hierarchical clustering algorithm invocated inside our cfg file and with parameter specified via command-line (```--rcluster-max 10``` option).
Let's have a look at the resulting partitioning scheme:

```
cat Analyses/BI/analysis/best_scheme.txt
```

As you can see this file contains similar informations to ModelFinder. Moreover it includes the MrBayes nexus block (necessary to run it):

```
begin mrbayes;

	charset Subset1 = 152-314 1-151 315-475;
	charset Subset2 = 476-805;
	charset Subset3 = 806-956;

	partition PartitionFinder = 3:Subset1, Subset2, Subset3;
	set partition=PartitionFinder;

	lset applyto=(1) rates=gamma;
	prset applyto=(1) aamodelpr=fixed(wag);
	lset applyto=(2) rates=gamma;
	prset applyto=(2) aamodelpr=fixed(vt);
	lset applyto=(3) rates=gamma;
	prset applyto=(3) aamodelpr=fixed(rtrev);

	prset applyto=(all) ratepr=variable;
	unlink statefreq=(all) revmat=(all) shape=(all) pinvar=(all) tratio=(all);

end;
```

---

<br/>
<br/>

## Bayesian Inference: 

Now we need to include this and other informations in a concatenated alignment in nexus format. Let's re-use AMAS to create a new concatenated alignment (yes again):

```
AMAS.py concat -u nexus -i Analyses/BI/Alignments/OG00000* -f fasta -d aa -t Analyses/BI/My_concat.nex
mv My_concat.nex Analyses/BI/
rm partitions.txt
```

Now let's open the resulting file and add the mrBayes block as follow:

 * **1.** add the MrBayes nexus block from PF results (should be inside ```Analyses/BI/analyses```) **after** the ```END;``` string of the nexus file.
 * **2.** add this line: ```mcmc ngen=500000 printfreq=5000 samplefreq=5000 nruns=2 nchains=4 temp=0.02;``` **after** the last line of the PF results but **before** the ```end``` statement.

This latest string specifies that:

* the analysis must run for **500k generations.**
* every **5k** parameters are printed to standard output.
* every **5k** parameters are sampled.
* **two independent runs** are carried out.
* each run is composed of **4 different chains**
* the temperature of the hot chain is **0.02**

While the first five parameters are quite straightforward, ```temp``` can be a little bit more obscure in the beginning (being somehow similar to the perturbance in IQTREE). The higher the temperature, the more likely the heated chains are to move between isolated peaks in the posterior distribution. However, excessive heating may lead to very low acceptance rates for swaps between different chains.

At the end your mrBayes block should look like this:

```
tail -n 27 Analyses/BI/My_concat.nex
	S_constricta     MFSSKEYLERKTGPYGIGRFSYLQSLVTEYQDTDDLDSKQQVMANLANFAYDPINYDHFRKLNILDIFL-DGLEEQDEKLVEFAVGGICNACLDKCLSRPNEETVLSAITSLMFLCTPGSKSDISCLPVVECMIRFSKAKNKRLSNLATVFMAYSVEKLLSDAAALCSRLKEHDSTADIIISMTQNLHKRIDAMKEYQDDITELNEIAKHRPRSYLVISIAQENRQIRDLQQENRDLRIALDEHQSALELIMKKYREQVNTLIETSKWEDKICEMANVMQ---KSVNVDEDASVADQQRLTQLEIENKGLRELLVCKYLATELKDRLEETGKTKEVLRLGQGLDDSKKRAVSYTTSELRLIEALTDPHICDKILEYNVHKERKGSLRFAKGQSETFKTLHNLVNKGVKVVMDVPYELWNHTPAEVTQLQKHCYQMVSVYEEEIEEWYFKHQ-DQPILDYLCRKHVP--QEERSSVNEVLATETQMFEKGATPSQSNQDLVR-GVNRKRSQSRNNRQMDKSLRLSAEQKCDIAQREIEELREEIDKLKEDSEKVLDTYKAIMEEADLRLAETKKESYEFDRDIMKGALNP-----STNKVVAEKVVRYFDDKIRSRDTLIEKLRLKNSTLKVQKKKLHLQLKQKEEMGEVLHEVDFNQLKIENQQYLEKIDERNQDLLRLKLMAGNTLQVLNSYKKKLHTLTMESERLKSEITSRNDLLTRIDAETSVVEVERAKAEKINKKLRQQLADFRVPEVMEYVSEKADLYELQKKVKSWERKVEIADMALRTHRKTWQQMKISHEMANQWDDELSIPRASLNKMIKEIIPNVRVANDARELILNCCTEFIHLVSTEANEICNKQMKKTISPEHVLAALDSLGFGNYKEDATTVLQEAKAVAAKKRRGSSRLQNLGIPEEELLRQQQELFAQARQEQAQLEQQQWQQMQQALQQQQQQQQQE

;

END;

begin mrbayes;

	charset Subset1 = 152-314 1-151 315-475;
	charset Subset2 = 476-805;
	charset Subset3 = 806-956;

	partition PartitionFinder = 3:Subset1, Subset2, Subset3;
	set partition=PartitionFinder;

	lset applyto=(1) rates=gamma;
	prset applyto=(1) aamodelpr=fixed(wag);
	lset applyto=(2) rates=gamma;
	prset applyto=(2) aamodelpr=fixed(vt);
	lset applyto=(3) rates=gamma;
	prset applyto=(3) aamodelpr=fixed(rtrev);

	prset applyto=(all) ratepr=variable;
	unlink statefreq=(all) revmat=(all) shape=(all) pinvar=(all) tratio=(all);
	mcmc ngen=500000 printfreq=5000 samplefreq=5000 nruns=2 nchains=4 temp=0.02;

end;
```
 
To run MrBayes just type:

```
conda install -c hcc mrbayes #Install mrBayes for MacOS user
conda install -c biobuild mrbayes #Installation for LINUX users
mb -i Analyses/BI/My_concat.nex
```

The program will instantly start writing to the standard output, *e.g.* the initial lnL of the four chains relative to the two runs:

```
      Initial log likelihoods and log prior probs for run 1:
         Chain 1 -- -12453.986041 -- 20.504472
         Chain 2 -- -12538.696635 -- 20.504472
         Chain 3 -- -12455.413128 -- 20.504472
         Chain 4 -- -12349.823398 -- 20.504472

      Initial log likelihoods and log prior probs for run 2:
         Chain 1 -- -12558.784539 -- 20.504472
         Chain 2 -- -12517.162610 -- 20.504472
         Chain 3 -- -12438.758998 -- 20.504472
         Chain 4 -- -12319.557676 -- 20.504472
```

While running, MrBayes will print the chain lnL, which are also written to the .p files. Along with the generation, the average standard deviation of split frequencies are printed: this values are a measure of similarity the tree toplogies sampled by the two independent runs and is highly informative of analysis convergence. It's usually considered that average standard deviation below 0.01 are quite good, values between 0.01 and 0.05 may be adequate depending on the purpose of your analysis, while higher value imply that the analysis is far from stationarity.

```
      Chain results (500000 generations requested):

          0 -- [-12453.986] (-12538.697) (-12455.413) (-12349.823) * [-12558.785] (-12517.163) (-12438.759) (-12319.558) 
       5000 -- [-10134.058] (-10139.817) (-10137.119) (-10137.438) * (-10138.877) (-10144.283) (-10144.509) [-10139.215] -- 2:20:15

      Average standard deviation of split frequencies: 0.265165
```

While running, MrBayes will print the chain lnL, which are also written to the .p files. Along with the generation, the average standard deviation of split frequencies are printed: this values are a measure of similarity the tree toplogies sampled by the two independent runs and is highly informative of analysis convergence. It's usually considered that average standard deviation below 0.01 are quite good, values between 0.01 and 0.05 may be adequate depending on the purpose of your analysis, while higher value imply that the analysis is far from stationarity.
